# long-form-generation-llm

1. FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation
2. Language Models Hallucinate, but May Excel at Fact Verification
3. RAGAS: Automated Evaluation of Retrieval Augmented Generation (sentence-level generation)
4. FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios
5. Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers
6. Towards LLM-based Fact Verification on News Claims with a Hierarchical Step-by-Step Prompting Method
7. Fine-tuning Language Models for Factuality
8. Chain-of-Verification Reduces Hallucination in Large Language Models
9. SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models
10. RARR: Researching and Revising What Language Models Say, Using Language Models
11. FELM: Benchmarking Factuality Evaluation of Large Language Models
12. Improving Model Factuality with Fine-grained Critique-based Evaluator
13. Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification
14. RAGBench: Explainable Benchmark for Retrieval-Augmented Generation Systems
15. FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation
16. 

